{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_limbs_length(self, joints):\n",
    "        limbs = []\n",
    "        limbs_len = np.zeros(len(params[\"limbs_point\"]))\n",
    "        for i, joint_indices in enumerate(params[\"limbs_point\"]):\n",
    "            if joints[joint_indices[0]] is not None and joints[joint_indices[1]] is not None:\n",
    "                limbs.append([joints[joint_indices[0]], joints[joint_indices[1]]])\n",
    "                limbs_len[i] = np.linalg.norm(joints[joint_indices[1]][:-1] - joints[joint_indices[0]][:-1])\n",
    "            else:\n",
    "                limbs.append(None)\n",
    "\n",
    "        return limbs_len, limbs\n",
    "\n",
    "def compute_unit_length(self, limbs_len):\n",
    "        unit_length = 0\n",
    "        base_limbs_len = limbs_len[[14, 3, 0, 13, 9]] # (鼻首、首左腰、首右腰、肩左耳、肩右耳)の長さの比率(このどれかが存在すればこれを優先的に単位長さの計算する)\n",
    "        non_zero_limbs_len = base_limbs_len > 0\n",
    "        if len(np.nonzero(non_zero_limbs_len)[0]) > 0:\n",
    "            limbs_len_ratio = np.array([0.85, 2.2, 2.2, 0.85, 0.85])\n",
    "            unit_length = np.sum(base_limbs_len[non_zero_limbs_len] / limbs_len_ratio[non_zero_limbs_len]) / len(np.nonzero(non_zero_limbs_len)[0])\n",
    "        else:\n",
    "            limbs_len_ratio = np.array([2.2, 1.7, 1.7, 2.2, 1.7, 1.7, 0.6, 0.93, 0.65, 0.85, 0.6, 0.93, 0.65, 0.85, 1, 0.2, 0.2, 0.25, 0.25])\n",
    "            non_zero_limbs_len = limbs_len > 0\n",
    "            unit_length = np.sum(limbs_len[non_zero_limbs_len] / limbs_len_ratio[non_zero_limbs_len]) / len(np.nonzero(non_zero_limbs_len)[0])\n",
    "\n",
    "        return unit_length\n",
    "\n",
    "\n",
    "def get_unit_length(self, person_pose):\n",
    "        limbs_length, limbs = self.compute_limbs_length(person_pose)\n",
    "        unit_length = self.compute_unit_length(limbs_length)\n",
    "\n",
    "        return unit_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ED_TCN(n_nodes, conv_len, n_classes, n_feat, max_len, \n",
    "            loss='categorical_crossentropy', causal=False, \n",
    "            optimizer=\"rmsprop\", activation='norm_relu',\n",
    "            return_param_str=False):\n",
    "    n_layers = len(n_nodes)\n",
    "\n",
    "    inputs = Input(shape=(max_len,n_feat))\n",
    "    model = inputs\n",
    "\n",
    "    # ---- Encoder ----\n",
    "    for i in range(n_layers):\n",
    "        # Pad beginning of sequence to prevent usage of future data\n",
    "        if causal: model = ZeroPadding1D((conv_len//2,0))(model)\n",
    "        model = Convolution1D(n_nodes[i], conv_len, border_mode='same')(model)\n",
    "        if causal: model = Cropping1D((0,conv_len//2))(model)\n",
    "\n",
    "        model = SpatialDropout1D(0.3)(model)\n",
    "        \n",
    "        if activation=='norm_relu': \n",
    "            model = Activation('relu')(model)            \n",
    "            model = Lambda(channel_normalization, name=\"encoder_norm_{}\".format(i))(model)\n",
    "        elif activation=='wavenet': \n",
    "            model = WaveNet_activation(model) \n",
    "        else:\n",
    "            model = Activation(activation)(model)            \n",
    "        \n",
    "        model = MaxPooling1D(2)(model)\n",
    "\n",
    "    # ---- Decoder ----\n",
    "    for i in range(n_layers):\n",
    "        model = UpSampling1D(2)(model)\n",
    "        if causal: model = ZeroPadding1D((conv_len//2,0))(model)\n",
    "        model = Convolution1D(n_nodes[-i-1], conv_len, border_mode='same')(model)\n",
    "        if causal: model = Cropping1D((0,conv_len//2))(model)\n",
    "\n",
    "        model = SpatialDropout1D(0.3)(model)\n",
    "\n",
    "        if activation=='norm_relu': \n",
    "            model = Activation('relu')(model)\n",
    "            model = Lambda(channel_normalization, name=\"decoder_norm_{}\".format(i))(model)\n",
    "        elif activation=='wavenet': \n",
    "            model = WaveNet_activation(model) \n",
    "        else:\n",
    "            model = Activation(activation)(model)\n",
    "            \n",
    "    # Output FC layer\n",
    "    model = TimeDistributed(Dense(n_classes, activation=\"softmax\" ))(model)\n",
    "    \n",
    "    model = Model(input=inputs, output=model)\n",
    "    model.compile(loss=loss, optimizer=optimizer, sample_weight_mode=\"temporal\", metrics=['accuracy'])\n",
    "\n",
    "    if return_param_str:\n",
    "        param_str = \"ED-TCN_C{}_L{}\".format(conv_len, n_layers)\n",
    "        if causal:\n",
    "            param_str += \"_causal\"\n",
    "    \n",
    "        return model, param_str\n",
    "    else:\n",
    "        return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
