{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_limbs_length(self, joints):\n",
    "        limbs = []\n",
    "        limbs_len = np.zeros(len(params[\"limbs_point\"]))\n",
    "        for i, joint_indices in enumerate(params[\"limbs_point\"]):\n",
    "            if joints[joint_indices[0]] is not None and joints[joint_indices[1]] is not None:\n",
    "                limbs.append([joints[joint_indices[0]], joints[joint_indices[1]]])\n",
    "                limbs_len[i] = np.linalg.norm(joints[joint_indices[1]][:-1] - joints[joint_indices[0]][:-1])\n",
    "            else:\n",
    "                limbs.append(None)\n",
    "\n",
    "        return limbs_len, limbs\n",
    "\n",
    "def compute_unit_length(self, limbs_len):\n",
    "        unit_length = 0\n",
    "        base_limbs_len = limbs_len[[14, 3, 0, 13, 9]] # (鼻首、首左腰、首右腰、肩左耳、肩右耳)の長さの比率(このどれかが存在すればこれを優先的に単位長さの計算する)\n",
    "        non_zero_limbs_len = base_limbs_len > 0\n",
    "        if len(np.nonzero(non_zero_limbs_len)[0]) > 0:\n",
    "            limbs_len_ratio = np.array([0.85, 2.2, 2.2, 0.85, 0.85])\n",
    "            unit_length = np.sum(base_limbs_len[non_zero_limbs_len] / limbs_len_ratio[non_zero_limbs_len]) / len(np.nonzero(non_zero_limbs_len)[0])\n",
    "        else:\n",
    "            limbs_len_ratio = np.array([2.2, 1.7, 1.7, 2.2, 1.7, 1.7, 0.6, 0.93, 0.65, 0.85, 0.6, 0.93, 0.65, 0.85, 1, 0.2, 0.2, 0.25, 0.25])\n",
    "            non_zero_limbs_len = limbs_len > 0\n",
    "            unit_length = np.sum(limbs_len[non_zero_limbs_len] / limbs_len_ratio[non_zero_limbs_len]) / len(np.nonzero(non_zero_limbs_len)[0])\n",
    "\n",
    "        return unit_length\n",
    "\n",
    "\n",
    "def get_unit_length(self, person_pose):\n",
    "        limbs_length, limbs = self.compute_limbs_length(person_pose)\n",
    "        unit_length = self.compute_unit_length(limbs_length)\n",
    "\n",
    "        return unit_length\n",
    "    \n",
    "    \n",
    "def channel_normalization(x):\n",
    "    # Normalize by the highest activation\n",
    "    max_values = K.max(K.abs(x), 2, keepdims=True)+1e-5\n",
    "    out = x / max_values\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, TimeDistributed, merge, Lambda\n",
    "from keras.layers.core import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.recurrent import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.activations import relu\n",
    "from functools import partial\n",
    "clipped_relu = partial(relu, max_value=5)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ED_TCN(n_nodes, conv_len, n_classes, n_feat, max_len, \n",
    "            loss='categorical_crossentropy', causal=False, \n",
    "            optimizer=\"rmsprop\", activation='norm_relu',\n",
    "            return_param_str=False):\n",
    "    n_layers = len(n_nodes)\n",
    "\n",
    "    inputs = Input(shape=(max_len,n_feat))\n",
    "    model = inputs\n",
    "\n",
    "    # ---- Encoder ----\n",
    "    for i in range(n_layers):\n",
    "        # Pad beginning of sequence to prevent usage of future data\n",
    "        if causal: model = ZeroPadding1D((conv_len//2,0))(model)\n",
    "        model = Convolution1D(n_nodes[i], conv_len, border_mode='same')(model)\n",
    "        if causal: model = Cropping1D((0,conv_len//2))(model)\n",
    "\n",
    "        model = SpatialDropout1D(0.3)(model)\n",
    "        \n",
    "        if activation=='norm_relu': \n",
    "            model = Activation('relu')(model)            \n",
    "            model = Lambda(channel_normalization, name=\"encoder_norm_{}\".format(i))(model)\n",
    "        elif activation=='wavenet': \n",
    "            model = WaveNet_activation(model) \n",
    "        else:\n",
    "            model = Activation(activation)(model)            \n",
    "        \n",
    "        model = MaxPooling1D(2)(model)\n",
    "\n",
    "    # ---- Decoder ----\n",
    "    for i in range(n_layers):\n",
    "        model = UpSampling1D(2)(model)\n",
    "        if causal: model = ZeroPadding1D((conv_len//2,0))(model)\n",
    "        model = Convolution1D(n_nodes[-i-1], conv_len, border_mode='same')(model)\n",
    "        if causal: model = Cropping1D((0,conv_len//2))(model)\n",
    "\n",
    "        model = SpatialDropout1D(0.3)(model)\n",
    "\n",
    "        if activation=='norm_relu': \n",
    "            model = Activation('relu')(model)\n",
    "            model = Lambda(channel_normalization, name=\"decoder_norm_{}\".format(i))(model)\n",
    "        elif activation=='wavenet': \n",
    "            model = WaveNet_activation(model) \n",
    "        else:\n",
    "            model = Activation(activation)(model)\n",
    "            \n",
    "    # Output FC layer\n",
    "    model = TimeDistributed(Dense(n_classes, activation=\"softmax\" ))(model)\n",
    "    \n",
    "    model = Model(input=inputs, output=model)\n",
    "    model.compile(loss=loss, optimizer=optimizer, sample_weight_mode=\"temporal\", metrics=['accuracy'])\n",
    "\n",
    "    if return_param_str:\n",
    "        param_str = \"ED-TCN_C{}_L{}\".format(conv_len, n_layers)\n",
    "        if causal:\n",
    "            param_str += \"_causal\"\n",
    "    \n",
    "        return model, param_str\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 200, 64)           160064    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_90 (Spatia (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "encoder_norm_0 (Lambda)      (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 100, 96)           153696    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_91 (Spatia (None, 100, 96)           0         \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 100, 96)           0         \n",
      "_________________________________________________________________\n",
      "encoder_norm_1 (Lambda)      (None, 100, 96)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 50, 96)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_45 (UpSampling (None, 100, 96)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 100, 96)           230496    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_92 (Spatia (None, 100, 96)           0         \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 100, 96)           0         \n",
      "_________________________________________________________________\n",
      "decoder_norm_0 (Lambda)      (None, 100, 96)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_46 (UpSampling (None, 200, 96)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 200, 64)           153664    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_93 (Spatia (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "decoder_norm_1 (Lambda)      (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 200, 10)           650       \n",
      "=================================================================\n",
      "Total params: 698,570\n",
      "Trainable params: 698,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daichi/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 25, padding=\"same\")`\n",
      "  \n",
      "/home/daichi/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(96, 25, padding=\"same\")`\n",
      "  \n",
      "/home/daichi/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(96, 25, padding=\"same\")`\n",
      "/home/daichi/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 25, padding=\"same\")`\n",
      "/home/daichi/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ti...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_nodes = [64, 96]\n",
    "conv = 25\n",
    "n_classes = 10\n",
    "n_feat = 100\n",
    "max_len = 200\n",
    "\n",
    "model, param_str = ED_TCN(n_nodes, conv, n_classes, n_feat, max_len, causal=False, activation='norm_relu', return_param_str=True)\n",
    "import json\n",
    "net = model.summary()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
